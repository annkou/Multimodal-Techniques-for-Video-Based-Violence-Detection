{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"../..\")))\n",
    "\n",
    "from models import clip, xclip\n",
    "from actions import helpers\n",
    "\n",
    "importlib.reload(clip)\n",
    "importlib.reload(xclip)\n",
    "importlib.reload(helpers)\n",
    "from models.clip import CLIPModel\n",
    "from models.xclip import XCLIPVideoClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIP_OUTPUT_JSON_PATH = \"../../data/results/clip_results.json\"\n",
    "XCLIP_OUTPUT_JSON_PATH = \"../../data/results/xclip_results.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get video paths and candidate labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "xd_violence = os.path.join(os.getenv(\"XD_VIOLENCE_PATH\"), \"abuse2.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vision_labels, associated_objects = helpers.extract_vision_data(\n",
    "    os.getenv(\"LABELS_PATH\")\n",
    ")\n",
    "primary_labels = list(vision_labels.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run CLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded CLIP model: openai/clip-vit-base-patch32\n"
     ]
    }
   ],
   "source": [
    "# 1. Initialize CLIP model\n",
    "clip_model = CLIPModel(\n",
    "    model_name=\"openai/clip-vit-base-patch32\",  # or \"openai/clip-vit-large-patch14\"\n",
    "    sample_rate=10,  # Extract every 10th frame\n",
    "    batch_size=8,  # Process 8 frames at a time\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1 videos\n"
     ]
    }
   ],
   "source": [
    "await clip_model.process_all_videos(\n",
    "    video_paths=[xd_violence],\n",
    "    candidate_labels=primary_labels,\n",
    "    output_json=CLIP_OUTPUT_JSON_PATH,\n",
    "    overwrite=False,  # Set to True to start fresh\n",
    "    top_k=3,  # Keep top 3 labels per frame\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1 videos\n"
     ]
    }
   ],
   "source": [
    "await clip_model.process_all_videos(\n",
    "    video_paths=[xd_violence],\n",
    "    candidate_labels=associated_objects,\n",
    "    output_json=CLIP_OUTPUT_JSON_PATH,\n",
    "    overwrite=False,  # Set to True to start fresh\n",
    "    top_k=3,  # Keep top 3 labels per frame\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run X-CLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded XCLIP model: microsoft/xclip-base-patch16-zero-shot\n"
     ]
    }
   ],
   "source": [
    "# Initialize X-CLIP model\n",
    "xclip_model = XCLIPVideoClassifier(\n",
    "    model_name=\"microsoft/xclip-base-patch16-zero-shot\",  # or \"microsoft/xclip-large-patch14\"\n",
    "    clip_len=32,  # Number of frames per segment\n",
    "    frame_sample_rate=2,  # Sample every 2nd frame\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await xclip_model.process_all_videos(\n",
    "    video_paths=[xd_violence],\n",
    "    labels=primary_labels,\n",
    "    output_json=XCLIP_OUTPUT_JSON_PATH,\n",
    "    overwrite=False,  # Set to True to start fresh\n",
    "    top_k=3,  # Keep top 3 labels per segment\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await xclip_model.process_all_videos(\n",
    "    video_paths=[xd_violence],\n",
    "    labels=associated_objects,\n",
    "    output_json=XCLIP_OUTPUT_JSON_PATH,\n",
    "    overwrite=False,  # Set to True to start fresh\n",
    "    top_k=3,  # Keep top 3 labels per segment\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multimodal-techniques-for-video-based-violence-detection-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
